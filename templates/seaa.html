<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SEAA Documentation</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f9;
            color: #333;
            line-height: 1.6;
        }
        .content {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3, h4, h5, h6 {
            color: #124E66;
            margin-top: 1.5em;
        }
        h1 { font-size: 2.5em; }
        h2 { font-size: 2em; }
        h3 { font-size: 1.5em; }
        a {
            color: #124E66;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            max-width: 100%;
            height: auto;
            margin: 20px 0;
        }
        ul, ol {
            padding-left: 20px;
        }
        code {
            background-color: #f0f0f0;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="content">
        <h1>SEAA</h1>

        <p>Semi-automatic anonimisation (SEAA) algorithm of the HU University of Applied Sciences Utrecht.</p>

        <h2>Summary</h2>
        <p>Open answers (an answer given to an open question) can contain privacy-related data. Currently, the most used methods of anonimisation at the HU is to do this by hand, to use non-anonimised data, or simple not use the data at all. The SEAA algorithm uses privacy-by-design as a fundamental principle: always make sure your data does not contain any privacy-related information. Using SEAA on your open answer data you can quickly identify which answers might contain privacy-related data and which answer do not. The answers that SEAA flags as 'might contain privacy-related data' can then be manually reviewed.</p>

        <h2>How does SEAA work?</h2>
        <img src="static/images/seaa_logo.png" alt="How SEAA works">
        <p>The algorithm uses both dictionairies and smart rules to determine if input (an answer to an open question) contains privacy-related data. SEAA will check for each answer if the words it contains are 'unknown' words (i.e. not part of the Dutch standard dictionary) as well as 'flagged' words (i.e. checking several blacklists for specific words related to privacy). An answer will be flagged as soon as it contains any unknown words and/or flagged words.</p>
        <p>The algorithm gives an advice in the form of 'Yes/No' whether the input contains privacy-related data. SEAA uses the 'privacy-by-default' rule: if the algorithm is not sure if an answer contains privacy-related information, it will always give back 'Yes'. Only when SEAA is 100% sure the input does not contain any privacy-related data, a 'No' will be adviced.</p>

        <h2>Dictionaries</h2>
        <p>SEAA uses a number different dictionaries, to determine unknown words as well as flagged words. The following dictionaries are combined and used to determine known words:</p>
        <ul>
            <li>Dutch language word list of <a href="https://www.opentaal.org/">OpenTaal</a>, the publiced wordlists 'basiswoorden-gekeurd' and 'flexies-ongekeurd' on their <a href="https://github.com/OpenTaal/opentaal-wordlist">GitHub</a></li>
            <li>HU Whitelist. Assembled by the project team with input from the stakeholders.</li>
        </ul>
        <p>Any words of an open answer that are not part of above dictionaries are flagged by SEAA as 'unknown' words.</p>
        <p>In addition, any words (known or unknown) that are part of the following dictionaries are flagged by SEAA as sensitive words:</p>
        <ul>
            <li>Dutch illness list (<a href="https://nl.wikipedia.org/wiki/Lijst_van_aandoeningen">Wikipedia</a>)</li>
            <li>Dutch first name list (<a href="https://nvb.meertens.knaw.nl/veelgesteldevragen">Nederlandse Voornamenbank</a>)</li>
            <li>Study limitations. Assembled by the project team with input from the stakeholders.</li>
            <li>Blacklist. Assembled by the project team with input from the stakeholders.</li>
        </ul>
        <p>Dictionaries are currently static, but will be added upon by stakeholders.</p>

        <h2>How can I use SEAA?</h2>
        <p>It is important to note that SEAA is only a tool and further work is needed on the data. When SEAA has given advice on your data, you are advised to use the 'contains_privacy' column that was added by SEAA to filter out all open answer that possibly contain privacy-related data. Only when this data is filtered, the remaining data is effectively anonimized and can be stored in another (more accessible) location and/or distributed (e.g. in a report). Furthermore, we strongly advise to use anonimised data as much as possible instead of unanonimised data. Unanonimised data should only be used by a small number of people, and only when strictly necessary.</p>
        <p>We do advice when sharing data anonimised by SEAA to always include a disclaimer that reads the following: "Deze data is geanonimiseerd. Zie je toch nog privacy-gerelateerde informatie? Neem dan contact op met ...", in which a contact number and/or emailaddress is added.</p>
        <p>In addition, any possible flaws in the SEAA algorithm can be flagged here in the GitHub repo as an issue.</p>

        <h2>Privacy & security</h2>
        <p>SEAA uses the privacy-by-design principle by always flagging an answer unless it only contains words that are deemed 'safe'. Words that are considered 'safe' are words part of the regular Dutch dictionary. In addition, an answer was also flagged as soon as it contains at least one word part of a sensitive word dictionary. For example, the answer 'Ik ben een docent' will not be flagged since it only contains 'safe' words, i.e. words part of the Dutch dictionary, and it contains no sensitive words. In contrast, the answer 'Ik heb een depressie' will be flagged. This answer contains only 'safe' words, i.e. words part of the Dutch dictionary, however, it also contains the sensitive word 'depressie' and therefor will be flagged (privacy first).</p>

        <h3>Privacy definitions</h3>
        <p>A strict privacy definition was needed to determine when an answer was considered to contain privacy-related data. Find below the privacy definitions we used to assess answers.</p>
        <p>In general SEAA follows the Dutch implementation of the GDPR as provided by the <a href="https://www.autoriteitpersoonsgegevens.nl/">Autoriteit Persoonsgegevens</a> (i.e. the <a href="https://www.autoriteitpersoonsgegevens.nl/en/about-the-dutch-dpa/tasks-and-powers-of-the-dutch-dpa">Dutch Data Protection Authority</a>). Since SEAA is an algorithm, a set of specified rules about when exactly privacy-concerns arise are needed. The enforcement of GDPR on data, however, is not specified in detail so a specific set of rules was defined based on the GDPR.</p>
        <p>A word and/or sequence of words is defined as "possibly containing privacy-related information" when one of the following:</p>
        <ul>
            <li>Contains information directly relatable to a person. That is:
                <ul>
                    <li>First name, last name</li>
                    <li>Email address</li>
                    <li>IP address</li>
                    <li>Address</li>
                    <li>Phone number</li>
                    <li>Student number</li>
                    <li>BSN number</li>
                    <li>Date of birth</li>
                </ul>
            </li>
            <li>Contains any mention of illness(type).</li>
        </ul>

        <h3>Security</h3>
        <p>SEAA is an algorithm that handles data that might contain privacy-related information, thus storing and handling this type of sensitive data is paramount. SEAA, as used by Team Data & Analytics of the HU, uses the following data architecture to ensure data safety:</p>
        <img src="static/images/flow.png" alt="Data Flow">
        <ol>
            <li>Data to enter SEAA (input) is stored in a secure OneDrive folder with only limited access. Only employees with explicit permissions are allowed to enter this data folder.</li>
            <li>SEAA is run in a local Python workspace in Visual Studio Code in which security is ensured through Windows security. This workspace concurrently uses data from the input folder (step 1) as well as code and/or docs present on the GitHub respository (<a href="https://github.com/uashogeschoolutrecht/SEAA">https://github.com/uashogeschoolutrecht/SEAA</a>). Please note that data or any other privacy-related information is never stored on GitHub, and this is enforced by explicit rules excluding data from uploading to GitHub.</li>
            <li>Results from SEAA are added back into the original data file, such that the same security from step 1 applies.</li>
        </ol>
        <p>Data in the secure OneDrive folder is only stored for the duration of the analysis.</p>

        <h2>Validation</h2>
        <p>SEAA was developed as a pilot to be ran on the open answer data of the National Student Questionaire (NSE) as requested by Hans Kruijer. During this phase (which ran from Sep '23 - Feb '24) the following stakeholders were involved:</p>
        <ul>
            <li>Team Institutional Research (product owner: Hans Kruijer)</li>
            <li>Team Data & Analytics</li>
            <li>Leonie Redder (opdrachtgever)</li>
            <li>Dick Vestdijk (privacy manager OO&S)</li>
        </ul>
        <p>During this pilot we developed SEAA to work as we intended and we tested this as following: SEAA was validated using open answer data of the National Student Questionaire (NSE) of 2023. In total a number of 2239 open answers were annotated by hand, i.e. manually indicating whether an answer contains privacy-related data. Annotations include a random draw from all NSE questions, as well as all answers from the question regarding study limitations and illness.</p>

        <h3>Pilot results</h3>
        <h4>Accuracy</h4>
        <p>Out of 2239 cases there were 11 cases where SEAA did not flag the answer even though it was annotated as containing privacy-related data. Examining these false negative cases in more depth showed that 10 out of 11 answers where falsely annotated as containing privacy-related data. One false negative case contained a reference to a car-accident ('auto-ongeluk').</p>
        <p>In conclusion, SEAA reached a very high accuracy of 99% while flagging answers from the National Student Questionaire (NSE) 2023.</p>

        <h4>Efficiency</h4>
        <p>Out of 2239 annotated cases, SEAA classified 1777 cases as not containing any privacy-related data, indicating an efficiency of 79%. In effect, using SEAA on this specific dataset would decrease the manual workload with 79%.</p>

        <h2>After the pilot</h2>
        <p>SEAA was further evaluated for organizational adoption by privacy officer Lisanne Reurings (Dienst Finance, Control & Analytics) and privacy manager Rinske Plomp.</p>
    </div>
</body>
</html> 